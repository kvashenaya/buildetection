{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\YaAlina\\\\ML_python\\\\projects\\\\buildetection_yolov8'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = 'C:\\\\Users\\\\YaAlina\\\\ML_python\\projects\\\\buildetection_yolov8'\n",
    "os.chdir(folder_path)\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "oyZJX6PVfE7J"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.yaml\") # build a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = 'C:\\\\Users\\\\YaAlina\\\\ML_python\\\\projects\\\\buildetection_yolov8\\\\model_train'\n",
    "data_path = os.path.join(ROOT_DIR, \"config.yaml\")\n",
    "learn_rate = 0.01\n",
    "opt_choice='AdamW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.221 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.145  Python-3.7.8 torch-1.10.0+cpu CPU (Intel Core(TM) i5-7200U 2.50GHz)\n",
      "WARNING  Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=C:\\Users\\YaAlina\\ML_python\\projects\\buildetection_yolov8\\model_train\\config.yaml, epochs=20, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train14\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv8n summary: 225 layers, 3011043 parameters, 3011027 gradients\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\YaAlina\\ML_python\\projects\\buildetection_yolov8\\datasets\\train\\labels.cache... 726 images, 0 b\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\YaAlina\\ML_python\\projects\\buildetection_yolov8\\datasets\\valid\\labels.cache... 47 images, 0 back\u001b[0m\n",
      "Plotting labels to runs\\detect\\train14\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train14\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/46 [00:00<?, ?it/s]C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\torch\\autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "       1/20         0G      2.942       2.78      3.538         18        640: 100%|██████████| 46/46 [12:11<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:21<0\n",
      "                   all         47         52      0.031      0.538     0.0846     0.0164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/20         0G      2.506      2.742      3.045         13        640: 100%|██████████| 46/46 [11:51<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<0\n",
      "                   all         47         52      0.031      0.538     0.0846     0.0164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/20         0G      2.112       2.65      2.768         18        640: 100%|██████████| 46/46 [11:47<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<0\n",
      "                   all         47         52      0.022      0.923        0.2     0.0495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/20         0G      1.954      2.545      2.637         24        640: 100%|██████████| 46/46 [11:46<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<0\n",
      "                   all         47         52    0.00412      0.769    0.00409    0.00084\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/20         0G      1.955      2.436      2.555         21        640: 100%|██████████| 46/46 [11:48<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<0\n",
      "                   all         47         52   0.000572      0.154   0.000366   6.49e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/20         0G      1.843      2.307      2.444         20        640: 100%|██████████| 46/46 [11:48<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<0\n",
      "                   all         47         52     0.0269      0.596     0.0239    0.00664\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/20         0G      1.775      2.167      2.394         20        640: 100%|██████████| 46/46 [11:48<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:18<0\n",
      "                   all         47         52      0.181     0.0577     0.0418    0.00887\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/20         0G      1.694      2.079      2.316         19        640: 100%|██████████| 46/46 [10:39<00:00, 13.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:14<0\n",
      "                   all         47         52     0.0208      0.288      0.015    0.00476\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/20         0G      1.654      1.963       2.24         22        640: 100%|██████████| 46/46 [09:59<00:00, 13.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:14<0\n",
      "                   all         47         52     0.0865      0.385     0.0665     0.0206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/20         0G      1.607       1.92      2.201         22        640: 100%|██████████| 46/46 [10:22<00:00, 13.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:16<0\n",
      "                   all         47         52      0.323      0.404      0.405      0.191\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/20         0G     0.9903      1.322      1.951          8        640: 100%|██████████| 46/46 [11:04<00:00, 14.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:14<0\n",
      "                   all         47         52      0.576      0.788       0.57      0.303\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/20         0G     0.8923     0.8977      1.851          7        640: 100%|██████████| 46/46 [09:36<00:00, 12.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:13<0\n",
      "                   all         47         52      0.773      0.462      0.522      0.265\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/20         0G     0.8644     0.8081      1.833          6        640: 100%|██████████| 46/46 [08:59<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:13<0\n",
      "                   all         47         52       0.93      0.769      0.848      0.487\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/20         0G     0.7565      0.717      1.718          6        640: 100%|██████████| 46/46 [08:55<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:13<0\n",
      "                   all         47         52      0.977      0.885        0.9      0.587\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/20         0G     0.7098     0.6587      1.669          7        640: 100%|██████████| 46/46 [08:57<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:13<0\n",
      "                   all         47         52      0.956      0.865      0.903      0.635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/20         0G     0.6486      0.616      1.586          7        640: 100%|██████████| 46/46 [08:58<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:14<0\n",
      "                   all         47         52      0.956      0.865       0.88      0.597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/20         0G     0.6272     0.5971      1.568          6        640: 100%|██████████| 46/46 [08:52<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:13<0\n",
      "                   all         47         52      0.956      0.865      0.896      0.606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/20         0G     0.6008     0.5528       1.55          7        640: 100%|██████████| 46/46 [08:51<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:13<0\n",
      "                   all         47         52       0.91      0.865      0.878      0.584\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/20         0G     0.5901     0.5203       1.55          8        640: 100%|██████████| 46/46 [08:51<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:13<0\n",
      "                   all         47         52      0.956      0.865      0.888      0.609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/20         0G     0.5429     0.4895      1.492          6        640: 100%|██████████| 46/46 [08:52<00:00, 11.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:14<0\n",
      "                   all         47         52      0.956      0.865      0.886      0.612\n",
      "\n",
      "20 epochs completed in 3.527 hours.\n",
      "Optimizer stripped from runs\\detect\\train14\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train14\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train14\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.145  Python-3.7.8 torch-1.10.0+cpu CPU (Intel Core(TM) i5-7200U 2.50GHz)\n",
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:12<0\n",
      "                   all         47         52      0.956      0.865      0.903      0.635\n",
      "Speed: 3.5ms preprocess, 242.4ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train14\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(data=data_path, epochs=20, lr0=learn_rate, optimizer=opt_choice)  # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.145  Python-3.7.8 torch-1.10.0+cpu CPU (Intel Core(TM) i5-7200U 2.50GHz)\n",
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\YaAlina\\ML_python\\projects\\buildetection_yolov8\\datasets\\valid\\labels.cache... 47 images, 0 back\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:11<0\n",
      "                   all         47         52      0.956      0.865      0.903      0.635\n",
      "Speed: 3.9ms preprocess, 234.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\YaAlina\\ML_python\\projects\\buildetection_yolov8\\datasets\\test\\images\\346_A_jpg.rf.cd2d817e635121c1bae074de7ae4a898.jpg: 640x640 1 building, 234.6ms\n",
      "Speed: 7.0ms preprocess, 234.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results_train = model('C:\\\\Users\\\\YaAlina\\\\ML_python\\\\projects\\\\buildetection_yolov8\\\\datasets\\\\test\\\\images\\\\346_A_jpg.rf.cd2d817e635121c1bae074de7ae4a898.jpg', conf=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.145  Python-3.7.8 torch-1.10.0+cpu CPU (Intel Core(TM) i5-7200U 2.50GHz)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs\\detect\\train14\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (6.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 13...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  10.4s, saved as 'runs\\detect\\train14\\weights\\best.onnx' (11.7 MB)\n",
      "\n",
      "Export complete (12.4s)\n",
      "Results saved to \u001b[1mC:\\Users\\YaAlina\\ML_python\\projects\\buildetection_yolov8\\runs\\detect\\train14\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs\\detect\\train14\\weights\\best.onnx imgsz=640 \n",
      "Validate:        yolo val task=detect model=runs\\detect\\train14\\weights\\best.onnx imgsz=640 data=None \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "model_success = model.export(format=\"onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 buildings, 1: 640x640 1 building, 475.0ms\n",
      "Speed: 9.0ms preprocess, 237.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model(['C:\\\\Users\\\\YaAlina\\\\ML_python\\\\projects\\\\buildetection_yolov8\\\\datasets\\\\test\\\\images\\\\1_jpg.rf.a67b4acad439253c394299bb103366cd.jpg', 'C:\\\\Users\\\\YaAlina\\\\ML_python\\\\projects\\\\buildetection_yolov8\\\\datasets\\\\test\\\\images\\\\121_A_jpg.rf.f58c479f1a8125b3030f47889db548b8.jpg'])  # return a list of Results objects\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    masks = result.masks \n",
    "    keypoints = result.keypoints \n",
    "    probs = result.probs  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
